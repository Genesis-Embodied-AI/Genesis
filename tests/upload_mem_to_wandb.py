"""
Upload memory benchmark results to Weights & Biases.

This script parses the memory CSV file generated by monitor_test_mem.py
and uploads all tests' memory usage to a single W&B run.

To test this use e.g.:

test,max_mem_mb
test_speed[franka-None-True-30000-gpu],123
test_blah[franka-None-True-3000-cpu],255

... and check that uploads to
https://wandb.ai/genesis-ai-company/genesis-benchmarks-mem/table
correctly
"""

import argparse
import wandb
import csv
import os
import re
import sys
from pathlib import Path

from utils import get_git_commit_info, pprint_oneline


def parse_test_name(test_name):
    """
    Expected format: test_speed[scenario-solver-flag-n_envs-backend]
    Example: test_speed[franka-None-True-30000-gpu]

    Returns:
        dict: Parsed parameters, e.g., {scenario: franka, n_envs: 30000, backend: gpu, flag: True}
    """
    # Extract parameters between brackets
    match = re.search(r"\[(.*?)\]", test_name)
    assert match

    parts = match.group(1).split("-")
    assert len(parts) >= 5

    params = {
        "scenario": parts[0],
        "solver": parts[1],
        "gjk": parts[2],
        "n_envs": parts[3],
        "backend": parts[4],
    }

    # Remove "None" values for consistency with alarm.yml parsing
    filtered_params = {}
    for k, v in params.items():
        if v != "None" and v is not None:
            filtered_params[k] = v

    return filtered_params


def upload_memory_to_wandb(mem_csv_path):
    """
    Parse memory CSV and upload all test results to a single W&B run.
    """
    revision, _ = get_git_commit_info()
    print(f"Uploading memory metrics to W&B for revision: {revision}")

    uploaded_count = 0
    skipped_count = 0

    # Initialize a single run for all benchmark results
    run = wandb.init(
        project="genesis-benchmarks-mem",
        name=f"memory-{revision[:12]}",
        config={
            "revision": revision,
        },
        settings=wandb.Settings(
            x_disable_stats=True,
            console="off",
        ),
    )

    with open(mem_csv_path) as f:
        reader = csv.DictReader(f)

        for row in reader:
            test_name = row["test"]
            max_mem_mb = float(row["max_mem_mb"])

            params = parse_test_name(test_name)

            # Create benchmark ID matching alarm.yml format
            # Format: memory-scenario=franka-n_envs=30000-backend=gpu-flag=True
            benchmark_id = f"memory-{pprint_oneline(params, delimiter='-')}"

            print(f"ðŸ“Š Uploading {benchmark_id}: {max_mem_mb:.0f} MB")

            # Log each benchmark result with its ID as the metric name
            run.log({benchmark_id: max_mem_mb})

            uploaded_count += 1

    run.finish()

    print(f"\nâœ… Memory upload complete: {uploaded_count} uploaded, {skipped_count} skipped")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--in-mem-csv-filepath", required=True)
    args = parser.parse_args()
    return upload_memory_to_wandb(mem_csv_path=args.in_mem_csv_filepath)


if __name__ == "__main__":
    main()
